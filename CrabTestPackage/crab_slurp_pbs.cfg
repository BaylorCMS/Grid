[CMSSW]
total_number_of_events  = 10000
number_of_jobs          = 5
pset                    = slurp.py
#datasetpath             = /GenericTTbar/SAM-CMSSW_5_3_1_START53_V5-v1/GEN-SIM-RECO 
#datasetpath             = /RelValTTbar_13/CMSSW_7_1_0_pre4_GEANT10-POSTLS171_V1-v1/GEN-SIM-RECO 
datasetpath             = /GenericTTbar/HC-CMSSW_7_0_4_START70_V7-v1/GEN-SIM-RECO
output_file             = outfile.root

[USER]
return_data              = 1
#copy_data               = 1
#storage_element         = T3_US_Baylor
#user_remote_dir         = CrabTest_Slurp_remoteGlidein
#user_remote_dir         = CrabTest_Slurp_CondorG
#user_remote_dir         = CrabTest_Slurp_Pbs
#user_remote_dir         = CrabTest_Slurp_Condor

[CRAB]
#scheduler = remoteGlidein
#scheduler = condor_g
#scheduler = glite
#scheduler = condor
scheduler = pbsv2
jobtype = cmssw

use_server = 0

[GRID]
#rb = CERN
#ce_white_list = T3_US_Baylor
se_white_list = T3_US_Baylor
#se_white_list = T3_US_Colorado
#ce_white_list = T3_US_FNALLPC
#se_white_list = T3_US_FNALLPC

data_location_override = T3_US,T2_US

#max_wall_clock_time = 1440
# in minutes (1440 minutes = 24 hours)

[PBSV2]
#grouplist=jswhep
#workernodebase=/tmp
#hostname=kodiak-ce.baylor.edu
# YOU MUST TUNE THE WALL TIME TO THE CORRECT LENGTH
# Too long a wall time will make your jobs less likely to get scheduled
# Too short a wall time will cause your jobs to get slayed by the scheduler
#resources=walltime=10:00:00,pmem=2800mb,mem=2800mb
#queue=batch
resources=walltime=2:00:00

#[CONDORG]
#globus_rsl= (maxWalltime=120)
# in minutes (120 minutes = 2 hours)
#globus_rsl= (queue=batch)(maxWalltime=119)(maxMemory=1900)
#resources= walltime=1:59:00
